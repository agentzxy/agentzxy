{"title":"scrapy框架爬取豆瓣电影top250","date":"2019-11-13T16:46:00.000Z","author":"Xinyi Zhang","link":"post/crapy框架爬取豆瓣电影top250","updated":"2019-11-13T17:16:53.367Z","content":"<p>在items里主要有五个item：序号、电影名字、电影标签、评分、图片url</p>\n<p>由于只爬取了电影，所以movie.py里只有电影这一个spider。里面的parse函数利用xpath将搜索出来的数据导入items里的各个item的列表中，<br>具体代码如下：</p>\n<pre><code>def parse(self, response):\n    html=response.text\n    html=etree.HTML(html)\n    order=html.xpath(&apos;//ol[@class=&quot;grid_view&quot;]/li/div/div/em&apos;)#序号\n    title=html.xpath(&apos;//ol[@class=&quot;grid_view&quot;]/li/div/div[@class=&quot;pic&quot;]/a/img/@alt&apos;)         inq=html.xpath(&apos;//ol[@class=&quot;grid_view&quot;]/li/div/div[@class=&quot;info&quot;]/div[@class=&quot;bd&quot;]/p[@class=&quot;quote&quot;]/span&apos;)        rating_num=html.xpath(&apos;//ol[@class=&quot;grid_view&quot;]/li/div/div[@class=&quot;info&quot;]/div[@class=&quot;bd&quot;]/div/span[@class=&quot;rating_num&quot;]&apos;)        image_url=html.xpath(&apos;//ol[@class=&quot;grid_view&quot;]/li/div/div[@class=&quot;pic&quot;]/a/img/@src&apos;)\n    item=movieItem()\n    item[&apos;nums&apos;]=order\n    item[&apos;names&apos;]=title\n    item[&apos;tags&apos;]=inq\n    item[&apos;scores&apos;]=rating_num\n    item[&apos;images&apos;]=image_url\n    yield item</code></pre><p>   注意一定要yield item，不然无法对items里面的进行数据处理</p>\n<p>   然后就是利用pipeline对数据处理，分为三个，分别是原始的、传入mysql的、将剧照保存的。</p>\n<p>   传入mysql：</p>\n<pre><code>def process_item(self,item,spider):\n    for i in range(24):\n        sql=&quot;INSERT INTO top250(NUM,NAME,TAG,SCORE) VALUES(%s,%s,%s,%s)&quot;\n        num=item[&apos;nums&apos;][i].text\n        name=item[&apos;names&apos;][i]\n        tag=item[&apos;tags&apos;][i].text\n        score=item[&apos;scores&apos;][i].text\n        s=(num,name,tag,score)\n        self.cursor.execute(sql,s)\n    self.db.commit()\n    return item</code></pre><p>   保存图片的：</p>\n<pre><code>def process_item(self,item,spider):\n    for i in range(24):\n        splitPath=item[&apos;images&apos;][i].split(&apos;.&apos;)\n        fTail=splitPath.pop()\n        fileName=item[&apos;names&apos;][i]+&quot;.&quot;+fTail\n        filepath=&quot;D:/ddddd/&quot;+fileName\n        request.urlretrieve(item[&apos;images&apos;][i],filepath)</code></pre><p>  最后就是在settings里面设置一些参数，具体代码参见<a href=\"https://github.com/agentzxy/Scrapy\" target=\"_blank\" rel=\"noopener\">github</a></p>\n","next":{"title":"Hello World","link":"post/hello-world"},"plink":"http://agentzxy.github.io/post/crapy框架爬取豆瓣电影top250/"}